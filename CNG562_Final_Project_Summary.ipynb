{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNG562_Final_Project_Summary.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BurakKizilkaya/Machine-Learning-Final-Project/blob/master/CNG562_Final_Project_Summary.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43Xma8Rcw4ci",
        "colab_type": "text"
      },
      "source": [
        "# CNG 562 Final Project Summary\n",
        "\n",
        "\n",
        "## Participants (Ordered by Surname)\n",
        "\n",
        "1. Participant #1: Burak, KIZILKAYA, 2331668\n",
        "2. Participant #2: Hakan Yekta YATBAZ, 2398089\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKomgxk9w4cj",
        "colab_type": "text"
      },
      "source": [
        "## Problem Description\n",
        "\n",
        "This project aims to provide a robust model to classify forest fires. Since it is a crucial problem, finding autonomous solution to detect forest fires becomes inevitable. The most challenging part of the project is creating dataset to establish a machine learning model as the literature has quite limited in terms of available data. Generally, there are datasets which are used to detect fires using smoke images. Our aim is detecting fire from still images and especially to detect forest fires. To achieve the tasks specified, firstly, well-known image classification neural networks are examined and the best combination of hyperparameters along with the most suitable architecture are researched for the model. Secondly, for the dataset generation, close-up forest fire videos are examined and the necessary frames are extracted with a label. Labeling operation is verified via double checking the images by hand. Having completing the fire labeled images, similar approach is repeated for non-fire labeled forest images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNgVJrzuw4cl",
        "colab_type": "text"
      },
      "source": [
        "## Data Description\n",
        "\n",
        "This project requires variety of images from forest fires. To be able to gather those, multiple image sources (videos) are used since there is no public image dataset to use forest fire detection. Forest fire videos collected from YouTube and sampled between 30-600 frame based on the camera's movement. Manual elimination is performed to avoid incorrect labeling. Generated dataset has  1111 fire images form 16 videos and 2289 non fire images from 9 videos.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZVGSgBbw4cm",
        "colab_type": "text"
      },
      "source": [
        "## Solution Description\n",
        "\n",
        "This project aims to build a learning model for images to distinguish between  image with fire and without fire. To achieve so,  CNN based models are examined due to its popularity and accuracy. \n",
        "\n",
        "Before implementing the models, some modifications are done on images to fix the input dimensions of the models and to have some variations. These modifications are;\n",
        "* Convert Image Size to 64x64\n",
        "* Random Horizontal Flip\n",
        "* For PyTorch Models, Random Rotation between -15 and 15 degrees.\n",
        "* For PyTorch Models, Normalization with mean 0.5 and standard deviation 0.5  for all channels (R,G,B)\n",
        "\n",
        "For this purpose we mainly test 3 different CNN models that we have built, and modified some of the well known Deep CNN models. The models generated and tested are implemented in two different framworks called Keras and PyTorch. The models (solutions) are described below;\n",
        "\n",
        "**Model 1 : Keras**\n",
        "*   Four Convolutional Layer\n",
        "      1.  Number of Kernels: 32-32-32-32\n",
        "      2.  Kernel Sizes: 3x3\n",
        "      3.  Pooling: Max Pooling(2x2)\n",
        "* Batch Size: 32\n",
        "* Two Fully Connected Layers\n",
        "* Activation Function: RELU\n",
        "* Optimizer: ADAM\n",
        "* Loss Function: Cross Entropy\n",
        "* Training Details\n",
        "     1. Epochs: 30\n",
        "     2. Learnng Rate: 1 (Keras Default)\n",
        "     \n",
        "---\n",
        "\n",
        "**Model 2 : Pytorch (Model 1 in Solution)**\n",
        "*   Four Convolutional Layer\n",
        "      1.  Number of Kernels: 32-32-32-32\n",
        "      2.  Kernel Sizes: 3x3\n",
        "      3.  Pooling: Max Pooling(2x2)\n",
        "* Three Fully Connected Layers\n",
        "* Batch Size: 32\n",
        "* Activation Function: RELU\n",
        "* Dropout Rate: 0.25\n",
        "* Optimizer: Stochastic Gradient Descent\n",
        "* Loss Function: Cross Entropy\n",
        "* Training Details\n",
        "     1. Epochs: 100\n",
        "     2. Learnng Rate: 0.01\n",
        "     3. Threshold for Convergence: 0.05\n",
        "   \n",
        "---\n",
        "\n",
        "**Model 3 : Pytorch (Model 3 in Solution)**\n",
        "*   Four Convolutional Layer\n",
        "      1.  Number of Kernels: 32-64-128-256\n",
        "      2.  Kernel Sizes: 3x3\n",
        "      3.  Pooling: Max Pooling(2x2)\n",
        "* Three Fully Connected Layers\n",
        "* Batch Size: 32\n",
        "* Activation Function: RELU\n",
        "* Dropout Rate: 0.25\n",
        "* Optimizer: Stochastic Gradient Descent\n",
        "* Loss Function: Cross Entropy\n",
        "* Training Details\n",
        "     1. Epochs: 100\n",
        "     2. Learnng Rate: 0.01\n",
        "     3. Threshold for Convergence: 0.05\n",
        "\n",
        "---\n",
        "\n",
        "**ResNet50: Keras** \n",
        "* Batch Size: 32\n",
        "* Activation Function: RELU\n",
        "* Optimizer: ADAM\n",
        "* Loss Function: Binary Entropy\n",
        "* Epochs : 30\n",
        "---\n",
        "\n",
        "**DenseNet : Pytorch**\n",
        "\n",
        "* Modifications In Fully Connected Layers\n",
        "  * Initial Architecture: One Fully Connected Layer (*Number of Input Units:* 1024->1000) \n",
        "  * Modified Architecture: Two Fully Connected Layer with RELU activation (*Number of Input Units:* 1024->500->2)\n",
        "* Optimizer: ADAM\n",
        "* Loss Function: Negative Log Likelihood\n",
        "* Epochs: 30\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**VGG 16 : Pytorch**\n",
        "\n",
        "* Modifications In Fully Connected Layers\n",
        "  * Initial Architecture: Three Fully Connected Layer (*Number of Input Units:* 25088->4096->4096->1000)\n",
        "  * Modified Architecture: Eight Fully Connected Layer with RELU activation (*Number of Input Units:* 25088->4096->2048->1024->512->256->128->64->2)\n",
        "* Optimizer: ADAM\n",
        "* Loss Function: Negative Log Likelihood\n",
        "* Epochs: 30\n",
        "* Learning Rate: 0.003\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vI_eqpjiw4cn",
        "colab_type": "text"
      },
      "source": [
        "## Project Results\n",
        "\n",
        "Results obtained for all the models are presented below.\n",
        "\n",
        "Model | Accuracy Score (%)\n",
        "--- | ---\n",
        "Model 1     | 99.12\n",
        "Model 2     | 98.68\n",
        "Model 3     | 99.56\n",
        "ResNet50  | 83.70\n",
        "DenseNet  | 99.00\n",
        "VGG16       | 98.00\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqGto6yh2loG",
        "colab_type": "text"
      },
      "source": [
        "## Discussion\n",
        "\n",
        "For this project, there were two main tasks, one is generating a dataset and the other is building a proper model. Although the results obtained are very high, they might be biased because of the dataset. On the other hand, we have tested the dataset with random images (single image test code is provided for Keras) and obtained good predictions for those random images. In addition, we believe that overfitting problem is minimized by using a validation set. In other words, as we save the model considering the decrease in validation loss and not the training loss, the overfitting should not be a problem. However, as described in the beginnging of this section, we could not find a systematic way to validate the dataset generated. All in all, considering all the other publications in this area, it could be said that it is a good first step to try CNN models on forest fire detection.\n",
        "\n",
        "In addition, there was a challenge that we tackled during the development of this project which was to gather images for forest fire detection. Even though there were many forest images thorughout the Internet, finding a proper fire image or video was problematic. To illustrate, we were able to extract 900 forest fire images from 13 different videos where collecting 2000 non-fire forest images took only 5 long videos. Thanks to  PyTorch's and Keras's libraries, building the model was not a problem. However,  when we first tried with larger image sizes, the training time was quite long, especially for transfer learning.\n",
        "\n",
        "All in all,  in this project we have learned how to build CNN models or how to use  pretrained models provided in different frameworks. In addition, we have understood the importance of publicly available data and importance of using a well-known dataset along with the long and hard process of creating a new dataset."
      ]
    }
  ]
}